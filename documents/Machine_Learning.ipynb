{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('trip_Nov_1to14_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(n=10000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "to_drop=['trips_pooled', 'shared_trip_authorized']\n",
    "\n",
    "X=data.drop(to_drop, axis=1)\n",
    "y=data['shared_trip_authorized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0, stratify = y)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "# def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "#                         n_jobs=None, train_sizes=np.linspace(.0001, .001, 10)):\n",
    "#     \"\"\"\n",
    "#     Generate 3 plots: the test and training learning curve, the training\n",
    "#     samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "#         An object of that type which is cloned for each validation.\n",
    "\n",
    "#     title : string\n",
    "#         Title for the chart.\n",
    "\n",
    "#     X : array-like, shape (n_samples, n_features)\n",
    "#         Training vector, where n_samples is the number of samples and\n",
    "#         n_features is the number of features.\n",
    "\n",
    "#     y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "#         Target relative to X for classification or regression;\n",
    "#         None for unsupervised learning.\n",
    "\n",
    "#     axes : array of 3 axes, optional (default=None)\n",
    "#         Axes to use for plotting the curves.\n",
    "\n",
    "#     ylim : tuple, shape (ymin, ymax), optional\n",
    "#         Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "#     cv : int, cross-validation generator or an iterable, optional\n",
    "#         Determines the cross-validation splitting strategy.\n",
    "#         Possible inputs for cv are:\n",
    "\n",
    "#           - None, to use the default 5-fold cross-validation,\n",
    "#           - integer, to specify the number of folds.\n",
    "#           - :term:`CV splitter`,\n",
    "#           - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "#         For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "#         :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "#         or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "#         Refer :ref:`User Guide <cross_validation>` for the various\n",
    "#         cross-validators that can be used here.\n",
    "\n",
    "#     n_jobs : int or None, optional (default=None)\n",
    "#         Number of jobs to run in parallel.\n",
    "#         ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "#         ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "#         for more details.\n",
    "\n",
    "#     train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "#         Relative or absolute numbers of training examples that will be used to\n",
    "#         generate the learning curve. If the dtype is float, it is regarded as a\n",
    "#         fraction of the maximum size of the training set (that is determined\n",
    "#         by the selected validation method), i.e. it has to be within (0, 1].\n",
    "#         Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "#         Note that for classification the number of samples usually have to\n",
    "#         be big enough to contain at least one sample from each class.\n",
    "#         (default: np.linspace(0.1, 1.0, 5))\n",
    "#     \"\"\"\n",
    "#     if axes is None:\n",
    "#         _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "#     axes[0].set_title(title)\n",
    "#     if ylim is not None:\n",
    "#         axes[0].set_ylim(*ylim)\n",
    "#     axes[0].set_xlabel(\"Training examples\")\n",
    "#     axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "#     train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "#         learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "#                        train_sizes=train_sizes,\n",
    "#                        return_times=True)\n",
    "#     train_scores_mean = np.mean(train_scores, axis=1)\n",
    "#     train_scores_std = np.std(train_scores, axis=1)\n",
    "#     test_scores_mean = np.mean(test_scores, axis=1)\n",
    "#     test_scores_std = np.std(test_scores, axis=1)\n",
    "#     fit_times_mean = np.mean(fit_times, axis=1)\n",
    "#     fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "#     # Plot learning curve\n",
    "#     axes[0].grid()\n",
    "#     axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "#                          train_scores_mean + train_scores_std, alpha=0.1,\n",
    "#                          color=\"r\")\n",
    "#     axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "#                          test_scores_mean + test_scores_std, alpha=0.1,\n",
    "#                          color=\"g\")\n",
    "#     axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "#                  label=\"Training score\")\n",
    "#     axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "#                  label=\"Cross-validation score\")\n",
    "#     axes[0].legend(loc=\"best\")\n",
    "\n",
    "#     # Plot n_samples vs fit_times\n",
    "#     axes[1].grid()\n",
    "#     axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "#     axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "#                          fit_times_mean + fit_times_std, alpha=0.1)\n",
    "#     axes[1].set_xlabel(\"Training examples\")\n",
    "#     axes[1].set_ylabel(\"fit_times\")\n",
    "#     axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "#     # Plot fit_time vs score\n",
    "#     axes[2].grid()\n",
    "#     axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "#     axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "#                          test_scores_mean + test_scores_std, alpha=0.1)\n",
    "#     axes[2].set_xlabel(\"fit_times\")\n",
    "#     axes[2].set_ylabel(\"Score\")\n",
    "#     axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "#     return plt\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "\n",
    "# title = \"Learning Curves (RandomForest Classifier)\"\n",
    "# # Cross validation with 100 iterations to get smoother mean test and train\n",
    "# # score curves, each time with 20% data randomly selected as a validation set.\n",
    "# cv = ShuffleSplit(n_splits=20, test_size=0.2, random_state=0)\n",
    "\n",
    "# estimator = RandomForestClassifier()\n",
    "# plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01),\n",
    "#                     cv=cv, n_jobs=4)\n",
    "\n",
    "# title = \"Learning Curves (GradientBoostingClassifier)\"\n",
    "# cv = ShuffleSplit(n_splits=20, test_size=0.2, random_state=0)\n",
    "# estimator = GradientBoostingClassifier()\n",
    "# plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.7, 1.01),\n",
    "#                     cv=cv, n_jobs=4)\n",
    "\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: 3.789397181613058\n",
      "------------------------\n",
      "train score accuracy 0.8925714285714286\n",
      "test score accuracy 0.8948571428571429\n",
      "------------------------\n",
      "train score precision 0.0\n",
      "test score precision 0.0\n",
      "------------------------\n",
      "train score recall 0.0\n",
      "test score recall 0.0\n",
      "------------------------\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      3132\n",
      "           1       0.00      0.00      0.00       368\n",
      "\n",
      "    accuracy                           0.89      3500\n",
      "   macro avg       0.45      0.50      0.47      3500\n",
      "weighted avg       0.80      0.89      0.85      3500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elhamamini/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/elhamamini/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=0).fit(X_train, y_train)\n",
    "\n",
    "dummy_pred=dummy.predict(X_test)\n",
    "dummy_probs = dummy.predict_proba(X_test)\n",
    "\n",
    "print('log_loss:', log_loss(y_test, dummy_probs))\n",
    "print('--'*12)\n",
    "print('train score accuracy', dummy.score(X_train, y_train))\n",
    "print('test score accuracy', dummy.score(X_val, y_val))\n",
    "print('--'*12)\n",
    "\n",
    "print('train score precision', precision_score(y_val, dummy_pred))\n",
    "print('test score precision', precision_score(y_val, dummy_pred))\n",
    "print('--'*12)\n",
    "print('train score recall', recall_score(y_val, dummy_pred))\n",
    "print('test score recall', recall_score(y_val, dummy_pred))\n",
    "print('--'*12)\n",
    "print('\\n')\n",
    "print(classification_report(y_val, dummy_pred, labels=[0, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: 0.4744675393660643\n",
      "------------------------\n",
      "train score accuracy 0.9634285714285714\n",
      "test score accuracy 0.964\n",
      "------------------------\n",
      "train score precision 1.0\n",
      "test score precision 1.0\n",
      "------------------------\n",
      "train score recall 0.657608695652174\n",
      "test score recall 0.657608695652174\n",
      "------------------------\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3132\n",
      "           1       1.00      0.66      0.79       368\n",
      "\n",
      "    accuracy                           0.96      3500\n",
      "   macro avg       0.98      0.83      0.89      3500\n",
      "weighted avg       0.97      0.96      0.96      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=7).fit(X_train, y_train)\n",
    "rf_pred=rf.predict(X_val)\n",
    "rf_probs = rf.predict_proba(X_val)\n",
    "\n",
    "print('log_loss:', log_loss(y_test, rf_probs))\n",
    "print('--'*12)\n",
    "print('train score accuracy', rf.score(X_train, y_train))\n",
    "print('test score accuracy', rf.score(X_val, y_val))\n",
    "print('--'*12)\n",
    "\n",
    "print('train score precision', precision_score(y_val, rf_pred))\n",
    "print('test score precision', precision_score(y_val, rf_pred))\n",
    "print('--'*12)\n",
    "print('train score recall', recall_score(y_val, rf_pred))\n",
    "print('test score recall', recall_score(y_val, rf_pred))\n",
    "print('--'*12)\n",
    "print('\\n')\n",
    "print(classification_report(y_val, rf_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_small = data.sample(n=10000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "to_drop=['trips_pooled', 'shared_trip_authorized']\n",
    "\n",
    "X=trip_small.drop(to_drop, axis=1)\n",
    "y=trip_small['shared_trip_authorized']\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X_new = SelectKBest(chi2, k=5).fit_transform(X, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new,y, test_size=0.3, random_state=0, stratify = y)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=5, max_features=5,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/rf_model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "scoring = ['precision','f1', 'recall']\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [5, 10, 50, 100, 200],\n",
    "    'max_depth': [1, 2, 3, 5],\n",
    "    'n_jobs': [-1, 0, 1],\n",
    "    'max_features':[1,2,3,4,5]\n",
    "    \n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf, parameters, cv=5, refit='recall', scoring=scoring)\n",
    "cv.fit(X_train,y_train)\n",
    "print(cv.best_estimator_)\n",
    "joblib.dump(cv.best_estimator_, 'models/rf_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "scoring = ['precision','f1', 'recall']\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, penalty='l1', solver='liblinear', n_jobs=-1)\n",
    "\n",
    "parameters = {\n",
    "    'C': [0.1, 1]\n",
    "}\n",
    "\n",
    "\n",
    "cv = GridSearchCV(lr, parameters, cv=5, refit='recall', scoring=scoring)\n",
    "cv.fit(X_train,y_train)\n",
    "print(cv.best_estimator_)\n",
    "joblib.dump(cv.best_estimator_, 'models/lr_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "scoring = ['precision','f1', 'recall']\n",
    "svc = SVC()\n",
    "\n",
    "parameters = {\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "\n",
    "cv = GridSearchCV(svc, parameters, cv=5,refit='recall', scoring=scoring )\n",
    "cv.fit(X_train,y_train)\n",
    "print(cv.best_estimator_)\n",
    "joblib.dump(cv.best_estimator_, 'models/svc_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "scoring = ['precision','f1', 'recall']\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 7],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(gb, parameters, cv=5, refit='recall', scoring=scoring )\n",
    "cv.fit(X_train,y_train)\n",
    "print(cv.best_estimator_)\n",
    "joblib.dump(cv.best_estimator_, 'models/gb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for mdl in ['rf', 'lr', 'svc','gb']:\n",
    "    models[mdl] = joblib.load(f'clean_data/models/{mdl}_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def evaluate_model(name, model, X_val, y_val):\n",
    "    start = time()\n",
    "    \n",
    "    pred = model.predict(X_val)\n",
    "    #probs = model.predict_proba(X_val)\n",
    "    \n",
    "    #log_loss_score = log_loss(y_val, probs)\n",
    "    accuracy = model.score(X_val, y_val)\n",
    "    precision = precision_score(y_val, pred)\n",
    "    recall = recall_score(y_val, pred)\n",
    "    f1 = f1_score(y_val, pred, average='weighted')\n",
    "    end = time()\n",
    "    \n",
    "    #print(f'{name} -- log_loss: {log_loss_score} Latency: {round(end-start, 2)}')\n",
    "    print(f'{name} -- accuracy: {accuracy} Latency: {round(end-start, 2)}')\n",
    "    print(f'{name} -- precision: {precision} Latency: {round(end-start, 2)}')\n",
    "    print(f'{name} -- recall: {recall} Latency: {round(end-start, 2)}')\n",
    "    print(f'{name} -- f1_score: {f1} Latency: {round(end-start, 2)}')\n",
    "    \n",
    "    print('--'*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, mdl in models.items():\n",
    "    evaluate_model(name, mdl, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model('gb', models['gb'], X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "percision_point = 0.75\n",
    "fpr_point = 0.16\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "\n",
    "y_lr = GradientBoostingClassifier(max_depth=7,learning_rate=0.1, n_estimators=100).fit(X_train, y_train).decision_function(X_test)\n",
    "    \n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_lr)\n",
    "closest_zero = np.argmin(np.abs(thresholds))\n",
    "closest_zero_p = precision[closest_zero]\n",
    "closest_zero_r = recall[closest_zero]\n",
    "\n",
    "\n",
    "precision_index = np.where(np.isclose(precision, percision_point))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.xlim([0.0, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.plot(precision, recall, label='Precision-Recall Curve')\n",
    "plt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\n",
    "plt.xlabel('Precision', fontsize=16)\n",
    "plt.ylabel('Recall', fontsize=16)\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()\n",
    "plt.savefig('images/precision_recall_curve.png')\n",
    "\n",
    "fpr, tpr,_ = roc_curve(y_test, y_lr)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.plot(fpr, tpr, lw=3, label='Gradient Boosting ROC curve (area = {:0.2f})'.format(roc_auc))\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.savefig('images/roc_curve.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
